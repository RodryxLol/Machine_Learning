Examen Machine Learning ‚Äì Home Credit Default Risk (Clasificaci√≥n)
Proyecto completo de Machine Learning desarrollado como examen final, utilizando el dataset Home Credit Default Risk (Kaggle). El proyecto implementa un flujo end-to-end basado en la metodolog√≠a CRISP-DM, estructurado como microservicios, con buenas pr√°cticas de ingenier√≠a de software y despliegue del modelo final como una API REST mediante FastAPI.

Contexto del Negocio
Una instituci√≥n financiera busca mejorar su proceso de evaluaci√≥n de solicitudes de cr√©dito. El objetivo es estimar la probabilidad de que un solicitante incurra en incumplimiento de pago (default), con el fin de minimizar p√©rdidas financieras, automatizar decisiones de aprobaci√≥n y derivar casos intermedios a revisi√≥n manual.

Objetivo T√©cnico
Construir un modelo de clasificaci√≥n binaria que permita predecir el riesgo de default integrando m√∫ltiples fuentes de datos, aplicando ingenier√≠a de caracter√≠sticas agregadas, manejando desbalance de clases y alta dimensionalidad, y sirviendo el modelo mediante una API REST consumible por otros sistemas.

Supuestos y Limitaciones del Modelo
El modelo de predicci√≥n de riesgo crediticio fue entrenado utilizando datos hist√≥ricos del dataset Home Credit Default Risk, por lo que se asume que los patrones de comportamiento observados en el pasado se mantienen en el tiempo. Sin embargo, cambios en el contexto econ√≥mico, pol√≠ticas crediticias o comportamiento de los solicitantes podr√≠an afectar el rendimiento futuro del modelo.

Dado que se trata de un modelo de clasificaci√≥n probabil√≠stica, sus predicciones no deben ser interpretadas como decisiones definitivas, sino como una herramienta de apoyo para la toma de decisiones. El sistema est√° dise√±ado para complementar el criterio humano, especialmente en los casos clasificados como riesgo intermedio.

Asimismo, el uso de variables agregadas provenientes de historiales financieros puede introducir sesgos indirectos, por lo que se recomienda un monitoreo continuo del desempe√±o del modelo y auditor√≠as peri√≥dicas para asegurar decisiones justas y responsables.

Justificaci√≥n de los Umbrales de Decisi√≥n
El endpoint /evaluate_risk devuelve una probabilidad de incumplimiento junto con una decisi√≥n sugerida basada en umbrales definidos desde una perspectiva de negocio.

Los umbrales se establecieron considerando:

El desbalance de clases presente en el dataset (default como clase minoritaria).

El alto costo financiero asociado a los falsos negativos (clientes con alta probabilidad de incumplimiento clasificados como seguros).

La necesidad de incorporar una zona de revisi√≥n manual para apoyar la toma de decisiones humanas.

La l√≥gica aplicada es la siguiente:

Probabilidad < 0.20 ‚Üí APROBAR Riesgo bajo de incumplimiento.

Probabilidad entre 0.20 y 0.35 ‚Üí REVISI√ìN MANUAL Zona de incertidumbre donde se recomienda an√°lisis adicional.

Probabilidad ‚â• 0.35 ‚Üí RECHAZAR Alto riesgo de incumplimiento.

Esta estrategia permite equilibrar automatizaci√≥n, control de riesgo y criterio humano.

Data Understanding (EDA)
La fase de Data Understanding se desarroll√≥ mediante un notebook interactivo ubicado en la carpeta 01_data_understanding/01_EDA.ipynb.

En este an√°lisis se abordaron los siguientes puntos:

Distribuci√≥n de la variable objetivo (TARGET) y an√°lisis del desbalance de clases.

Identificaci√≥n de valores nulos y porcentaje de missing values por variable.

Clasificaci√≥n de variables num√©ricas y categ√≥ricas.

An√°lisis preliminar de correlaciones y variables relevantes.

Obtenci√≥n de primeros insights para la etapa de feature engineering.

Adicionalmente, se gener√≥ un resumen ejecutivo del an√°lisis exploratorio en el archivo eda_summary.md.

Dataset
Se utiliza el dataset Home Credit Default Risk (Kaggle), compuesto por m√∫ltiples tablas relacionales. Las principales tablas empleadas en el proyecto son:

application_train.parquet
application_test.parquet
bureau.parquet
bureau_balance.parquet
previous_application.parquet
POS_CASH_balance.parquet
installments_payments.parquet
credit_card_balance.parquet
HomeCredit_columns_description.parquet
Todas las tablas se integran mediante feature engineering agregado previo al modelado.

Estructura del Proyecto (CRISP-DM / Microservicios)
El proyecto est√° organizado simulando un flujo de microservicios alineado con las fases de CRISP-DM:

EXAMEN_ML_HOME_CREDIT_FULL/

01_data_understanding/
Scripts y notebooks para an√°lisis exploratorio de datos (EDA).

02_data_preparation/
Scripts de limpieza, integraci√≥n de fuentes y feature engineering.

build_features.py
03_modeling/
Entrenamiento, validaci√≥n y selecci√≥n del modelo campe√≥n.

train_and_select.py
04_evaluation/
Evaluaci√≥n final del modelo, generaci√≥n de m√©tricas, visualizaciones y an√°lisis de errores.

evaluate_champion.py
05_deployment/
Despliegue del modelo como API REST utilizando FastAPI.

app.py
artifacts/
Almacenamiento de salidas del pipeline:

train_features.parquet
test_features.parquet
champion_model.joblib
model_metrics.json
evaluation_report.json
feature_schema.json
figures/ (ROC, PR, matriz de confusi√≥n, importancia de variables)
data/
Datos en formato parquet.

docs/
Documentaci√≥n adicional (opcional).

requirements.txt
README.md

Flujo CRISP-DM Implementado
El proyecto sigue el est√°ndar CRISP-DM, organizado en una arquitectura modular que simula microservicios:

Business Understanding Definici√≥n del problema de negocio y del objetivo de predicci√≥n de riesgo crediticio.

Data Understanding An√°lisis exploratorio de los datos (EDA), evaluaci√≥n de distribuci√≥n de la variable objetivo, valores nulos y tipos de variables.

Data Preparation Limpieza, integraci√≥n de m√∫ltiples fuentes de datos y creaci√≥n de variables agregadas mediante feature engineering.

Modeling Entrenamiento de modelos de clasificaci√≥n, manejo de desbalance y selecci√≥n del modelo campe√≥n mediante validaci√≥n cruzada.

Evaluation Evaluaci√≥n final del modelo con m√©tricas, visualizaciones y an√°lisis de errores.

Deployment Despliegue del modelo seleccionado como una API REST utilizando FastAPI, permitiendo su consumo externo.

Instalaci√≥n
Crear entorno virtual (opcional):

python -m venv .venv

Activar entorno (Windows):

.venv\Scripts\Activate.ps1

Instalar dependencias:

pip install -r requirements.txt

Ejecuci√≥n del Pipeline Completo
Paso 1 ‚Äì Feature Engineering:

python 02_data_preparation/build_features.py

Este paso integra todas las fuentes de datos y genera los datasets finales de entrenamiento y test en la carpeta artifacts.

Paso 2 ‚Äì Entrenamiento y Selecci√≥n del Modelo:

python 03_modeling/train_and_select.py

Se entrenan distintos modelos, se eval√∫an mediante validaci√≥n cruzada estratificada y se selecciona un modelo campe√≥n. El modelo final se guarda como champion_model.joblib.

Paso 3 ‚Äì Evaluaci√≥n Final:

python 04_evaluation/evaluate_champion.py

Se generan m√©tricas finales, curvas ROC y Precision-Recall, matriz de confusi√≥n, an√°lisis de errores y reporte completo en evaluation_report.json.

Paso 4 ‚Äì Despliegue como API:

python -m uvicorn 05_deployment.app:app --reload

Swagger UI disponible en:

http://127.0.0.1:8000/docs

Despliegue como API REST
El modelo final fue desplegado como una API REST utilizando FastAPI, permitiendo evaluar el riesgo crediticio de nuevos solicitantes mediante solicitudes HTTP en formato JSON.

Endpoints disponibles:

GET /health Verifica el estado de la API.

POST /evaluate_risk Eval√∫a el riesgo de incumplimiento de un solicitante y retorna:

probabilidad de default,

decisi√≥n sugerida de negocio,

umbrales utilizados.

Ejemplo de Request: { "features": { "AMT_CREDIT": 450000, "AMT_INCOME_TOTAL": 180000, "DAYS_BIRTH": -12000, "NAME_CONTRACT_TYPE": "Cash loans" } }

Ejemplo de Response: { "probability_default": 0.497, "decision": "RECHAZAR", "threshold_approve": 0.20, "threshold_reject": 0.35, "notes": "Regla: <0.20 APROBAR | 0.20-0.35 REVISI√ìN MANUAL | >=0.35 RECHAZAR" }

La documentaci√≥n interactiva se encuentra disponible en Swagger:

üëâ http://127.0.0.1:8000/docs

API ‚Äì Endpoints Disponibles
GET /health
Endpoint de verificaci√≥n del estado de la API y carga correcta del modelo.

POST /evaluate_risk
Eval√∫a el riesgo crediticio de un solicitante a partir de datos enviados en formato JSON.

Reglas de negocio para la decisi√≥n:

Probabilidad < 0.20 ‚Üí APROBAR
Probabilidad entre 0.20 y 0.35 ‚Üí REVISI√ìN MANUAL
Probabilidad ‚â• 0.35 ‚Üí RECHAZAR
Ejemplo de request:

{ "features": { "AMT_CREDIT": 450000, "AMT_INCOME_TOTAL": 180000, "DAYS_BIRTH": -12000, "NAME_CONTRACT_TYPE": "Cash loans" } }

Ejemplo de response:

{ "probability_default": 0.497033, "decision": "RECHAZAR", "threshold_approve": 0.2, "threshold_reject": 0.35, "notes": "Regla: <0.20 APROBAR | 0.20-0.35 REVISI√ìN MANUAL | >=0.35 RECHAZAR" }

Modelado y Evaluaci√≥n
Modelo principal: Logistic Regression con solver SAGA.
Manejo de desbalance: class_weight = balanced.
Codificaci√≥n categ√≥rica: OneHotEncoder en formato sparse.
Validaci√≥n: Stratified K-Fold Cross Validation.
M√©trica principal: ROC AUC.
An√°lisis complementario: Precision, Recall, matriz de confusi√≥n, permutation importance y an√°lisis de errores FP/FN.
Buenas Pr√°cticas Implementadas
Metodolog√≠a CRISP-DM completa.
C√≥digo modular y reproducible.
Separaci√≥n clara por etapas del pipeline.
Manejo de alta dimensionalidad.
API documentada autom√°ticamente con Swagger.
Reportes autom√°ticos en artifacts.
Enfoque de negocio incorporado en la toma de decisiones.
Uso de la API
Iniciar el servidor: uvicorn 05_deployment.app:app --reload

Acceder a Swagger: http://127.0.0.1:8000/docs

Probar el endpoint POST /evaluate_risk ingresando las variables del solicitante.
